{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/frankwillard/NBA-Web-Scraper-And-ANN/blob/main/Final_Web_Scraper.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "pL67RYudI43o"
      },
      "outputs": [],
      "source": [
        "# import needed libraries\n",
        "from urllib.request import urlopen\n",
        "from bs4 import BeautifulSoup\n",
        "import pandas as pd\n",
        "import re\n",
        "import numpy as np\n",
        "import lxml"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "q6AgcG13JJQL"
      },
      "outputs": [],
      "source": [
        "def remove_items(test_list, item):\n",
        "      \n",
        "    # using list comprehension to perform the task\n",
        "    res = [i for i in test_list if i != item]\n",
        "  \n",
        "    return res"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "CvlWKWItNXJq"
      },
      "outputs": [],
      "source": [
        "def multiple_replace(string, rep_dict):\n",
        "    pattern = re.compile(\"|\".join([re.escape(k) for k in sorted(rep_dict,key=len,reverse=True)]), flags=re.DOTALL)\n",
        "    return pattern.sub(lambda x: rep_dict[x.group(0)], string)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "TKsLs_uiI5yV"
      },
      "outputs": [],
      "source": [
        "# create a function to scrape team performance for multiple years\n",
        "def scrape_NBA_team_data(years = [2017, 2018]):\n",
        "\n",
        "    final_df = pd.DataFrame(columns = ['Year', 'Team', 'Age', 'W', 'L', 'PW', 'PL', 'MOV', 'SOS', 'SRS',\n",
        "       'ORtg', 'DRtg', 'NRtg', 'Pace', 'FTr', '3PAr', 'TS%', 'OeFG%', 'OTOV%',\n",
        "       'ORB%', 'OFT/FGA', 'DeFG%', 'DTOV%', 'DRB%', 'DFT/FGA', 'Arena', 'Attend.',\n",
        "       'Playoffs', 'W/L%', 'Losing_season'])\n",
        "\n",
        "    # loop through each year\n",
        "    for y in years:\n",
        "        # NBA season to scrape\n",
        "        year = y\n",
        "        \n",
        "        # URL to scrape, notice f string:\n",
        "        url = f\"https://www.basketball-reference.com/leagues/NBA_{year}.html\"\n",
        "        \n",
        "        # collect HTML data\n",
        "        html = urlopen(url)\n",
        "        \n",
        "        # create beautiful soup object from HTML\n",
        "        # soup = BeautifulSoup(html, \"lxml\")\n",
        "        soup = BeautifulSoup(html, 'html.parser')\n",
        "\n",
        "        league_champ_txt = soup.findAll(\"strong\")[1]\n",
        "\n",
        "        league_champ = league_champ_txt.find_next_sibling(\"a\").getText()\n",
        "\n",
        "\n",
        "        #rows = adv_table.tbody.find_all('tr')\n",
        "        \n",
        "        adv_table = soup.find(id='advanced-team')\n",
        "\n",
        "        adv_cols = [th.getText() for th in adv_table.findAll('tr', limit=2)[1].findAll('th')]\n",
        "        adv_cols = remove_items(adv_cols, '\\xa0')\n",
        "        adv_cols.remove('Attend./G')\n",
        "\n",
        "        for i in [17,18,20]:\n",
        "          adv_cols[i]=\"O\"+adv_cols[i]\n",
        "        \n",
        "        for i in [21,22,24]:\n",
        "          adv_cols[i]=\"D\"+adv_cols[i]\n",
        "\n",
        "        #df = pd.DataFrame(columns=[\"Year\"].extend(adv_cols))\n",
        "\n",
        "        reg_dict = {\n",
        "            \"+\":\"\",\n",
        "            \",\":\"\"\n",
        "        }\n",
        "        \n",
        "        team_stats = []\n",
        "        j = 0\n",
        "\n",
        "        rows = adv_table.tbody.find_all('tr')\n",
        "        for row in rows:\n",
        "          columns = row.find_all('td')\n",
        "          team_stats.append([multiple_replace(columns[i].getText(), reg_dict) for i in range(len(columns)-1) if columns[i].getText() != ''])\n",
        "          # remove empty elements\n",
        "          #team_stats = [e for e in team_stats if e != []]\n",
        "          \n",
        "          # add team name to each row in team_stats\n",
        "        for i in range(0, len(team_stats)):\n",
        "            team_stats[i].insert(0, year)\n",
        "        \n",
        "        # add team, year columns to headers\n",
        "        adv_cols.insert(0, \"Year\")\n",
        "\n",
        "        adv_cols.remove(\"Rk\")\n",
        "        \n",
        "        # create a dataframe with all aquired info\n",
        "        year_standings = pd.DataFrame(team_stats, columns = adv_cols)        \n",
        "       \n",
        "        # add a column to dataframe to indicate playoff appearance\n",
        "        year_standings[\"Playoffs\"] = [\"Y\" if \"*\" in ele else \"N\" for ele in year_standings[\"Team\"]]\n",
        "\n",
        "        # remove * from team names\n",
        "        year_standings[\"Team\"] = [ele.replace('*', '') for ele in year_standings[\"Team\"]]\n",
        "\n",
        "        for col in year_standings.columns:\n",
        "          if col not in [\"Team\", \"Arena\", \"Playoffs\"]:\n",
        "            year_standings[col] = year_standings[col].astype(float)\n",
        "        # add losing season indicator (win % < .5)\n",
        "\n",
        "        year_standings[\"W/L%\"] = year_standings[\"W\"] / (year_standings[\"W\"] + year_standings[\"L\"])\n",
        "\n",
        "        year_standings[\"Losing_season\"] = [\"Y\" if float(ele) < .5 else \"N\" for ele in year_standings[\"W/L%\"]]\n",
        "\n",
        "        year_standings[\"Champion\"] = [\"Y\" if name == league_champ else \"N\" for name in year_standings[\"Team\"]]\n",
        "        \n",
        "        #for i in [17,18,20]:\n",
        "        #  year_standings = year_standings.rename(columns={year_standings.columns[i]: 'O'+year_standings.columns[i]})\n",
        "        \n",
        "        #for i in [21,22,25]:\n",
        "        #  year_standings = year_standings.rename(columns={year_standings.columns[i]: 'D'+year_standings.columns[i]})\n",
        "\n",
        "        #print(year_standings.columns)\n",
        "\n",
        "        # append new dataframe to final_df\n",
        "        final_df = pd.DataFrame(final_df)\n",
        "        final_df = pd.concat([final_df, year_standings])\n",
        "        # final_df = final_df.append(year_standings)\n",
        "    \n",
        "    final_df = final_df.sort_values(by=['Team', 'Year'])\n",
        "\n",
        "    lag_1 = final_df['Champion'].shift(1)\n",
        "\n",
        "    final_df['won_last'] = lag_1  # add to DataFrame\n",
        "\n",
        "    concat = final_df['Champion'].shift(1) + final_df['Champion'].shift(2) + final_df['Champion'].shift(3)\n",
        "\n",
        "    lag_3 = concat.str.contains(\"Y\")\n",
        "\n",
        "    pd.set_option('display.max_rows', 20)\n",
        "    \n",
        "    #print(lag_3)\n",
        "\n",
        "    final_df['won_last_3'] = [\"Y\" if lagger else \"N\" for lagger in lag_3]  # add to DataFrame\n",
        "    \n",
        "    final_df = final_df[final_df.Year > 1989.0]\n",
        "\n",
        "    final_df = final_df.sort_values(by=['Year', 'Team'])\n",
        "\n",
        "    # print final_df\n",
        "    # print(final_df.info)\n",
        "    # export to csv\n",
        "    final_df.to_csv(\"nba_team_advanced_data.csv\", index=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LNg8Y-nRI7gh",
        "outputId": "ffd432ea-e97c-477c-c45c-56930f685ac8"
      },
      "outputs": [],
      "source": [
        "scrape_NBA_team_data(years = [1987, 1988, 1989, 1990, 1991, 1992, 1993, 1994,\n",
        "                              1995, 1996, 1997, 1998, 1999,\n",
        "                              2000, 2001, 2002, 2003, 2004,\n",
        "                              2005, 2006, 2007, 2008, 2009,\n",
        "                              2010, 2011, 2012, 2013, 2014,\n",
        "                              2015, 2016, 2017, 2018, 2019,\n",
        "                              2020, 2021, 2022])"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "authorship_tag": "ABX9TyOPJxK4YHGrbWauu1neFQYx",
      "include_colab_link": true,
      "name": "Final Web Scraper (Playoffs)",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3.10.6 ('venv': venv)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.6"
    },
    "vscode": {
      "interpreter": {
        "hash": "8c7fb1509f04aa6739f4ee98284bc089a906977093f13d0e429c2e4fad8d27e8"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
